{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm \n",
    "from datasets import load_dataset\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "sns.set_palette(sns.color_palette('husl', 8))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "params = {\n",
    "    'legend.fontsize': 'x-large',\n",
    "    'figure.figsize': (16, 5),\n",
    "    'axes.labelsize': 'x-large',\n",
    "    'axes.titlesize':'x-large',\n",
    "    'xtick.labelsize':'x-large',\n",
    "    'ytick.labelsize':'x-large',\n",
    "}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "from src.loading import huggingface_dataset_to_dataframes\n",
    "from src.preprocessing import Preprocessor\n",
    "from src.feature_engineering import FeatureEngineering\n",
    "from src.bias import Factors\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Load human learning datasets\n",
    "test_axis, validation_axis = (\n",
    "    pd.read_pickle(\"data/raw/test_axis.pkl\"),\n",
    "    pd.read_pickle(\"data/raw/validation_axis.pkl\"),\n",
    ")\n",
    "train_comparisons, validation_comparisons = (\n",
    "    pd.read_pickle(\"data/raw/train_comparisons.pkl\").iloc[:10000],\n",
    "    pd.read_pickle(\"data/raw/validation_comparisons.pkl\").iloc[:10000],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. Pre-processing\n",
    "preprocessor = Preprocessor()\n",
    "\n",
    "train_comparisons = preprocessor.preprocessing_pipeline(train_comparisons)\n",
    "validation_comparisons = preprocessor.preprocessing_pipeline(validation_comparisons)\n",
    "\n",
    "test_axis = preprocessor.preprocessing_pipeline(test_axis)\n",
    "validation_axis = preprocessor.preprocessing_pipeline(validation_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 106.96977233886719 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# 3. Feature engineering\n",
    "fe = FeatureEngineering()\n",
    "\n",
    "train_comparisons = fe.fe_pipeline(train_comparisons, \"comparisons\") \n",
    "validation_comparisons = fe.fe_pipeline(validation_comparisons, \"comparisons\")\n",
    "                                                \n",
    "test_axis = fe.fe_pipeline(test_axis, \"axis\") \n",
    "validation_axis = fe.fe_pipeline(validation_axis, \"axis\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My boyfriend and I are long distance. We have a trip planned this summer which involves me going over to him in the USA. This will be the second time I have actually been with him in person. I am flying from the UK with my mum to the east coast. The original plan was for me to fly over to my boyfriend in the west coast (my parents are holidaying on the east coast) but because my mum was freaking out so much about me going to meet my boyfriend i said we can all road trip there together. I even invited her on the trip with us. I have given her all of our dates so that she can travel around with us.\\n\\nThe plan was for me to stay on the 4th July and fly back on the 5th. Mum knew this. I told her I had booked a flight back already from the west coast to east coast (where she would pick me up and we would fly back to the UK together). She has gone mad at me because she can't believe I would book a flight when she told me she didn't want me flying on my own. At the time I had booked it she told me she wasn't gonna road trip with us. She knew the trip was happening.......how else was I to get home if I don't fly? \\n\\nI am fine flying on my own it doesn't bother me at all. I feel like I have done everything I can to make her feel comfortable with this trip and she is just trying to sabotage it. Thoughts??\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comparisons.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mum is mad at me for not flying on my own trip to meet my boyfriend.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comparisons.summary_0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "    \n",
    "def compute_reference_free_metrics(text: str, summary: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Compute reference-free metrics.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def compression_ratio() -> float:\n",
    "        \"\"\"\n",
    "        Compression Ratio. How much the algorithm has condensed the original \n",
    "        text.\n",
    "        \n",
    "        \"\"\"\n",
    "        return len(summary) / len(text)\n",
    "    \n",
    "    def jaccard_similarity(n_grams) -> float:\n",
    "        \"\"\"\n",
    "        Jaccard Similarity: Jaccard Similarity is a measure of the similarity \n",
    "        between two sets. It is calculated as the size of the intersection of \n",
    "        the sets divided by the size of their union. This metric measures the \n",
    "        overlap of words (tokens) between the input text and the generated \n",
    "        summary. A higher Jaccard Similarity indicates a larger degree of \n",
    "        shared words between the input and the summary. However, this metric \n",
    "        might not capture the quality of the summary, especially if the \n",
    "        algorithm rephrases or paraphrases the content.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Tokens\n",
    "        input_tokens = word_tokenize(text)\n",
    "        summary_tokens = word_tokenize(summary)\n",
    "        \n",
    "        if n_grams > 1:\n",
    "            input_set = set(ngrams(input_tokens, n_grams))\n",
    "            summary_set = set(ngrams(summary_tokens, n_grams))\n",
    "        else:\n",
    "            input_set = set(input_tokens)\n",
    "            summary_set = set(summary_tokens)\n",
    "            \n",
    "        # Intersection and union\n",
    "        intersection = input_set.intersection(summary_set)\n",
    "        union = input_set.union(summary_set)\n",
    "        \n",
    "        return len(intersection) / len(union)  \n",
    "\n",
    "    return {\n",
    "        \"compression_ratio\": compression_ratio(),\n",
    "        \"jaccard_similarity_1\": jaccard_similarity(n_grams=1),\n",
    "        \"jaccard_similarity_2\": jaccard_similarity(n_grams=2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compression_ratio</th>\n",
       "      <th>jaccard_similarity_1</th>\n",
       "      <th>jaccard_similarity_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051750</td>\n",
       "      <td>0.107914</td>\n",
       "      <td>0.030418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.111888</td>\n",
       "      <td>0.029630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.070015</td>\n",
       "      <td>0.136691</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.127093</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.039568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.120353</td>\n",
       "      <td>0.129213</td>\n",
       "      <td>0.030100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.073345</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.129853</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.129853</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.061728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.105756</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.116466</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      compression_ratio  jaccard_similarity_1  jaccard_similarity_2\n",
       "0              0.051750              0.107914              0.030418\n",
       "1              0.095890              0.111888              0.029630\n",
       "2              0.070015              0.136691              0.045455\n",
       "3              0.127093              0.154930              0.039568\n",
       "4              0.120353              0.129213              0.030100\n",
       "...                 ...                   ...                   ...\n",
       "9995           0.073345              0.075000              0.020000\n",
       "9996           0.129853              0.166667              0.036364\n",
       "9997           0.129853              0.195652              0.061728\n",
       "9998           0.105756              0.125000              0.031056\n",
       "9999           0.116466              0.145833              0.030303\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comparisons.apply(\n",
    "    lambda row: compute_reference_free_metrics(\n",
    "        row['text'], \n",
    "        row['summary_0']\n",
    "    ), \n",
    "    axis=1\n",
    ").apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding sentences\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"Embedding sentences\")\n",
    "\n",
    "# data = pd.read_csv(\"data/sentences.csv\")\n",
    "\n",
    "# sentences = data['utterance'].tolist()\n",
    "\n",
    "# sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "# data['vector'] = sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffbc08f68b3049ae895a64656e2ebcd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9f99b56678406d8cc6ec3a8826044a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(\n",
    "    train_comparisons['text'], batch_size=64, convert_to_tensor=True, show_progress_bar=True)\n",
    "embeddings2 = model.encode(\n",
    "    train_comparisons['summary_0'], batch_size=64, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       My boyfriend and I are long distance. We have ...\n",
       "1       My boyfriend and I are long distance. We have ...\n",
       "2       My boyfriend and I are long distance. We have ...\n",
       "3       My boyfriend and I are long distance. We have ...\n",
       "4       My landlord left a falsified message taped to ...\n",
       "                              ...                        \n",
       "9995    Hey all I just got back from seeing a friend w...\n",
       "9996    I know that every guy watches porn, but I don'...\n",
       "9997    I know that every guy watches porn, but I don'...\n",
       "9998    I know that every guy watches porn, but I don'...\n",
       "9999    I know that every guy watches porn, but I don'...\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comparisons['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The original plan was for me to fly over to my boyfriend in the west coast (my parents are holidaying on the east coast) but because my mum was freaking out so much about me going to meet my boyfriend i said we can all road trip there together.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(train_comparisons.text[0], words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pytextrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.sparse' has no attribute 'coo_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-2612aa8cbaa3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# add PyTextRank to the spaCy pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"textrank\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# examine the top-ranked phrases in the document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1014\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE109\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m                 \u001b[0merror_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturned_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mraise_error\u001b[1;34m(proc_name, proc, docs, e)\u001b[0m\n\u001b[0;32m   1687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1688\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproc_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1689\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1009\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1011\u001b[1;33m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1012\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m                 \u001b[1;31m# This typically happens if a component is not initialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytextrank\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    251\u001b[0m             )\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphrases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtextrank\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_textrank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytextrank\\base.py\u001b[0m in \u001b[0;36mcalc_textrank\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[1;31m# for PageRank (i.e., based on eigenvector centrality)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;31m# to calculate a rank for each node in the lemma graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         self.ranks = nx.pagerank(\n\u001b[0m\u001b[0;32m    353\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[0mpersonalization\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_personalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\networkx\\classes\\backends.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    146\u001b[0m                         \u001b[1;34mf\"'{name}' not implemented by {plugin_name}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                     )\n\u001b[1;32m--> 148\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;31m# Keep a handle to the original function to use when testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\networkx\\algorithms\\link_analysis\\pagerank_alg.py\u001b[0m in \u001b[0;36mpagerank\u001b[1;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \"\"\"\n\u001b[1;32m--> 110\u001b[1;33m     return _pagerank_scipy(\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpersonalization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdangling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\networkx\\algorithms\\link_analysis\\pagerank_alg.py\u001b[0m in \u001b[0;36m_pagerank_scipy\u001b[1;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[0mnodelist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_scipy_sparse_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodelist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnodelist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m     \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[0mS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mS\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mS\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\networkx\\convert_matrix.py\u001b[0m in \u001b[0;36mto_scipy_sparse_array\u001b[1;34m(G, nodelist, dtype, weight, format)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_directed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoo_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;31m# symmetrize matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scipy.sparse' has no attribute 'coo_array'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pytextrank\n",
    "\n",
    "# example text\n",
    "text = \"Compatibility of systems of linear constraints over the set of natural numbers. Criteria of compatibility of a system of linear Diophantine equations, strict inequations, and nonstrict inequations are considered. Upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given. These criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types systems and systems of mixed types.\"\n",
    "\n",
    "# load a spaCy model, depending on language, scale, etc.\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# add PyTextRank to the spaCy pipeline\n",
    "nlp.add_pipe(\"textrank\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# examine the top-ranked phrases in the document\n",
    "for phrase in doc._.phrases:\n",
    "    print(phrase.text)\n",
    "    print(phrase.rank, phrase.count)\n",
    "    print(phrase.chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>batch</th>\n",
       "      <th>split</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>subsource</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>summary_0</th>\n",
       "      <th>policy_0</th>\n",
       "      <th>note_0</th>\n",
       "      <th>summary_1</th>\n",
       "      <th>policy_1</th>\n",
       "      <th>note_1</th>\n",
       "      <th>confidence</th>\n",
       "      <th>choice</th>\n",
       "      <th>ref_summary</th>\n",
       "      <th>m0_rouge_1_f</th>\n",
       "      <th>m0_rouge_2_f</th>\n",
       "      <th>m0_rouge_l_f</th>\n",
       "      <th>m1_rouge_1_f</th>\n",
       "      <th>m1_rouge_2_f</th>\n",
       "      <th>m1_rouge_l_f</th>\n",
       "      <th>m0_bleu</th>\n",
       "      <th>m1_bleu</th>\n",
       "      <th>m0_flesch_reading_ease</th>\n",
       "      <th>m0_syllable_count</th>\n",
       "      <th>m0_lexicon_count</th>\n",
       "      <th>m0_sentence_count</th>\n",
       "      <th>m0_char_count</th>\n",
       "      <th>m0_letter_count</th>\n",
       "      <th>m0_polysyllab_count</th>\n",
       "      <th>m0_monosyllab_count</th>\n",
       "      <th>m1_flesch_reading_ease</th>\n",
       "      <th>m1_syllable_count</th>\n",
       "      <th>m1_lexicon_count</th>\n",
       "      <th>m1_sentence_count</th>\n",
       "      <th>m1_char_count</th>\n",
       "      <th>m1_letter_count</th>\n",
       "      <th>m1_polysyllab_count</th>\n",
       "      <th>m1_monosyllab_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_34xale</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>Mother  not speaking to me  because of a trip ...</td>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>Mum is mad at me for not flying on my own trip...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I have made sure my mother is comfortable with...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.057345</td>\n",
       "      <td>0.046340</td>\n",
       "      <td>97.54</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>71.48</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_34xale</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>Mother  not speaking to me  because of a trip ...</td>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>I have made sure my mother is comfortable with...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>ref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.48</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>77.57</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_34xale</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>Mother  not speaking to me  because of a trip ...</td>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>ref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mum thought I was going to road trip with my b...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>77.57</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97.20</td>\n",
       "      <td>38.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_34xale</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>Mother  not speaking to me  because of a trip ...</td>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>Mum thought I was going to road trip with my b...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mum is mad at me for not flying on my own trip...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.057345</td>\n",
       "      <td>97.20</td>\n",
       "      <td>38.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>97.54</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LjvoXOAj5op3WqNnn5b7TZTG8mK7gM</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_1zwek5</td>\n",
       "      <td>reddit</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>Can I sue my property management company and l...</td>\n",
       "      <td>My landlord left a falsified message taped to ...</td>\n",
       "      <td>My landlord is harassing me and my neighbours ...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>landlord pretended to be another tenant and wr...</td>\n",
       "      <td>ref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>landlord pretended to be another tenant and wr...</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.63</td>\n",
       "      <td>48.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.81</td>\n",
       "      <td>47.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           worker   batch  split         id  source  \\\n",
       "0  qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  batch3  train  t3_34xale  reddit   \n",
       "1  qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  batch3  train  t3_34xale  reddit   \n",
       "2  qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  batch3  train  t3_34xale  reddit   \n",
       "3  qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  batch3  train  t3_34xale  reddit   \n",
       "4  LjvoXOAj5op3WqNnn5b7TZTG8mK7gM  batch3  train  t3_1zwek5  reddit   \n",
       "\n",
       "       subsource                                              title  \\\n",
       "0  relationships  Mother  not speaking to me  because of a trip ...   \n",
       "1  relationships  Mother  not speaking to me  because of a trip ...   \n",
       "2  relationships  Mother  not speaking to me  because of a trip ...   \n",
       "3  relationships  Mother  not speaking to me  because of a trip ...   \n",
       "4      AskReddit  Can I sue my property management company and l...   \n",
       "\n",
       "                                                text  \\\n",
       "0  My boyfriend and I are long distance. We have ...   \n",
       "1  My boyfriend and I are long distance. We have ...   \n",
       "2  My boyfriend and I are long distance. We have ...   \n",
       "3  My boyfriend and I are long distance. We have ...   \n",
       "4  My landlord left a falsified message taped to ...   \n",
       "\n",
       "                                           summary_0 policy_0  note_0  \\\n",
       "0  Mum is mad at me for not flying on my own trip...     sup1     NaN   \n",
       "1  I have made sure my mother is comfortable with...     sup1     NaN   \n",
       "2  mum isn't speaking to me because I booked a fl...      ref     NaN   \n",
       "3  Mum thought I was going to road trip with my b...     sup1     NaN   \n",
       "4  My landlord is harassing me and my neighbours ...     sup1     NaN   \n",
       "\n",
       "                                           summary_1 policy_1  note_1  \\\n",
       "0  I have made sure my mother is comfortable with...     sup1     NaN   \n",
       "1  mum isn't speaking to me because I booked a fl...      ref     NaN   \n",
       "2  Mum thought I was going to road trip with my b...     sup1     NaN   \n",
       "3  Mum is mad at me for not flying on my own trip...     sup1     NaN   \n",
       "4  landlord pretended to be another tenant and wr...      ref     NaN   \n",
       "\n",
       "   confidence  choice                                        ref_summary  \\\n",
       "0         NaN       1  mum isn't speaking to me because I booked a fl...   \n",
       "1         NaN       1  mum isn't speaking to me because I booked a fl...   \n",
       "2         NaN       0  mum isn't speaking to me because I booked a fl...   \n",
       "3         NaN       0  mum isn't speaking to me because I booked a fl...   \n",
       "4         NaN       1  landlord pretended to be another tenant and wr...   \n",
       "\n",
       "   m0_rouge_1_f  m0_rouge_2_f  m0_rouge_l_f  m1_rouge_1_f  m1_rouge_2_f  \\\n",
       "0      0.363636      0.181818      0.303030      0.368421      0.100000   \n",
       "1      0.368421      0.100000      0.210526      1.000000      1.000000   \n",
       "2      1.000000      1.000000      1.000000      0.325581      0.000000   \n",
       "3      0.325581      0.000000      0.279070      0.363636      0.181818   \n",
       "4      0.137931      0.000000      0.137931      1.000000      1.000000   \n",
       "\n",
       "   m1_rouge_l_f   m0_bleu   m1_bleu  m0_flesch_reading_ease  \\\n",
       "0      0.210526  0.057345  0.046340                   97.54   \n",
       "1      1.000000  0.046340  1.000000                   71.48   \n",
       "2      0.279070  1.000000  0.008724                   77.57   \n",
       "3      0.303030  0.008724  0.057345                   97.20   \n",
       "4      1.000000  0.007511  1.000000                   70.63   \n",
       "\n",
       "   m0_syllable_count  m0_lexicon_count  m0_sentence_count  m0_char_count  \\\n",
       "0               17.0              16.0                1.0           53.0   \n",
       "1               32.0              25.0                1.0          102.0   \n",
       "2               24.0              19.0                1.0           74.0   \n",
       "3               38.0              32.0                4.0          136.0   \n",
       "4               48.0              35.0                2.0          157.0   \n",
       "\n",
       "   m0_letter_count  m0_polysyllab_count  m0_monosyllab_count  \\\n",
       "0             52.0                  0.0                 15.0   \n",
       "1            101.0                  2.0                 20.0   \n",
       "2             71.0                  0.0                 14.0   \n",
       "3            132.0                  1.0                 27.0   \n",
       "4            155.0                  4.0                 26.0   \n",
       "\n",
       "   m1_flesch_reading_ease  m1_syllable_count  m1_lexicon_count  \\\n",
       "0                   71.48               32.0              25.0   \n",
       "1                   77.57               24.0              19.0   \n",
       "2                   97.20               38.0              32.0   \n",
       "3                   97.54               17.0              16.0   \n",
       "4                   48.81               47.0              28.0   \n",
       "\n",
       "   m1_sentence_count  m1_char_count  m1_letter_count  m1_polysyllab_count  \\\n",
       "0                1.0          102.0            101.0                  2.0   \n",
       "1                1.0           74.0             71.0                  0.0   \n",
       "2                4.0          136.0            132.0                  1.0   \n",
       "3                1.0           53.0             52.0                  0.0   \n",
       "4                2.0          145.0            143.0                  7.0   \n",
       "\n",
       "   m1_monosyllab_count  \n",
       "0                 20.0  \n",
       "1                 14.0  \n",
       "2                 27.0  \n",
       "3                 15.0  \n",
       "4                 17.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comparisons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>batch</th>\n",
       "      <th>split</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>subsource</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>policy</th>\n",
       "      <th>note</th>\n",
       "      <th>compatible</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>coverage</th>\n",
       "      <th>coherence</th>\n",
       "      <th>overall</th>\n",
       "      <th>ref_summary</th>\n",
       "      <th>m_rouge_1_f</th>\n",
       "      <th>m_rouge_2_f</th>\n",
       "      <th>m_rouge_l_f</th>\n",
       "      <th>m_bleu</th>\n",
       "      <th>m_flesch_reading_ease</th>\n",
       "      <th>m_syllable_count</th>\n",
       "      <th>m_lexicon_count</th>\n",
       "      <th>m_sentence_count</th>\n",
       "      <th>m_char_count</th>\n",
       "      <th>m_letter_count</th>\n",
       "      <th>m_polysyllab_count</th>\n",
       "      <th>m_monosyllab_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iL7GfrbN2PeB3KInidqSxUdxYcTZmG</td>\n",
       "      <td>tldraxis1</td>\n",
       "      <td>valid2</td>\n",
       "      <td>t3_4l0bal</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>19f with fiance 20m and roommate 19m- fiance a...</td>\n",
       "      <td>Recently, my fiance  (20 m) and I (19f) moved ...</td>\n",
       "      <td>Fiance and I recently got infected with scabie...</td>\n",
       "      <td>sup4_ppo_rm4_t.7</td>\n",
       "      <td>'our apartment will not go away. I'm afraid he...</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>infestation of scabies mites in apartment, roo...</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>87.92</td>\n",
       "      <td>46.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iL7GfrbN2PeB3KInidqSxUdxYcTZmG</td>\n",
       "      <td>tldraxis1</td>\n",
       "      <td>valid2</td>\n",
       "      <td>t3_4l0bal</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>19f with fiance 20m and roommate 19m- fiance a...</td>\n",
       "      <td>Recently, my fiance  (20 m) and I (19f) moved ...</td>\n",
       "      <td>my fiance and I refuse to treat our room mate'...</td>\n",
       "      <td>pretrain_6b_t.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>infestation of scabies mites in apartment, roo...</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.007266</td>\n",
       "      <td>78.93</td>\n",
       "      <td>31.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iL7GfrbN2PeB3KInidqSxUdxYcTZmG</td>\n",
       "      <td>tldraxis1</td>\n",
       "      <td>valid2</td>\n",
       "      <td>t3_4l0bal</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>19f with fiance 20m and roommate 19m- fiance a...</td>\n",
       "      <td>Recently, my fiance  (20 m) and I (19f) moved ...</td>\n",
       "      <td>fiancÃ© and I contracted scabies, roommate refu...</td>\n",
       "      <td>sup4_6b_ppo_rm4_6b_t.7</td>\n",
       "      <td>the question s missing but the summary is good</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>infestation of scabies mites in apartment, roo...</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.014123</td>\n",
       "      <td>70.63</td>\n",
       "      <td>50.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iL7GfrbN2PeB3KInidqSxUdxYcTZmG</td>\n",
       "      <td>tldraxis1</td>\n",
       "      <td>valid2</td>\n",
       "      <td>t3_4l0bal</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>19f with fiance 20m and roommate 19m- fiance a...</td>\n",
       "      <td>Recently, my fiance  (20 m) and I (19f) moved ...</td>\n",
       "      <td>fiance and I are infected with scabies, room m...</td>\n",
       "      <td>sup4_6b_t0.7</td>\n",
       "      <td>a small inaccuracy and omission, otherwise good</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>infestation of scabies mites in apartment, roo...</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.009849</td>\n",
       "      <td>73.51</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iL7GfrbN2PeB3KInidqSxUdxYcTZmG</td>\n",
       "      <td>tldraxis1</td>\n",
       "      <td>valid2</td>\n",
       "      <td>t3_4l0bal</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>19f with fiance 20m and roommate 19m- fiance a...</td>\n",
       "      <td>Recently, my fiance  (20 m) and I (19f) moved ...</td>\n",
       "      <td>Fiance and I contracted scabies, roommate refu...</td>\n",
       "      <td>sup4_12b_t0.7</td>\n",
       "      <td>a small inaccuracy, otherwise good</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>infestation of scabies mites in apartment, roo...</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.016276</td>\n",
       "      <td>89.45</td>\n",
       "      <td>38.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           worker      batch   split         id  source  \\\n",
       "0  iL7GfrbN2PeB3KInidqSxUdxYcTZmG  tldraxis1  valid2  t3_4l0bal  reddit   \n",
       "1  iL7GfrbN2PeB3KInidqSxUdxYcTZmG  tldraxis1  valid2  t3_4l0bal  reddit   \n",
       "2  iL7GfrbN2PeB3KInidqSxUdxYcTZmG  tldraxis1  valid2  t3_4l0bal  reddit   \n",
       "3  iL7GfrbN2PeB3KInidqSxUdxYcTZmG  tldraxis1  valid2  t3_4l0bal  reddit   \n",
       "4  iL7GfrbN2PeB3KInidqSxUdxYcTZmG  tldraxis1  valid2  t3_4l0bal  reddit   \n",
       "\n",
       "             subsource                                              title  \\\n",
       "0  relationship_advice  19f with fiance 20m and roommate 19m- fiance a...   \n",
       "1  relationship_advice  19f with fiance 20m and roommate 19m- fiance a...   \n",
       "2  relationship_advice  19f with fiance 20m and roommate 19m- fiance a...   \n",
       "3  relationship_advice  19f with fiance 20m and roommate 19m- fiance a...   \n",
       "4  relationship_advice  19f with fiance 20m and roommate 19m- fiance a...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Recently, my fiance  (20 m) and I (19f) moved ...   \n",
       "1  Recently, my fiance  (20 m) and I (19f) moved ...   \n",
       "2  Recently, my fiance  (20 m) and I (19f) moved ...   \n",
       "3  Recently, my fiance  (20 m) and I (19f) moved ...   \n",
       "4  Recently, my fiance  (20 m) and I (19f) moved ...   \n",
       "\n",
       "                                             summary                  policy  \\\n",
       "0  Fiance and I recently got infected with scabie...        sup4_ppo_rm4_t.7   \n",
       "1  my fiance and I refuse to treat our room mate'...         pretrain_6b_t.7   \n",
       "2  fiancÃ© and I contracted scabies, roommate refu...  sup4_6b_ppo_rm4_6b_t.7   \n",
       "3  fiance and I are infected with scabies, room m...            sup4_6b_t0.7   \n",
       "4  Fiance and I contracted scabies, roommate refu...           sup4_12b_t0.7   \n",
       "\n",
       "                                                note  compatible  accuracy  \\\n",
       "0  'our apartment will not go away. I'm afraid he...       False       5.0   \n",
       "1                                                NaN       False       4.0   \n",
       "2     the question s missing but the summary is good       False       6.0   \n",
       "3    a small inaccuracy and omission, otherwise good       False       6.0   \n",
       "4                 a small inaccuracy, otherwise good       False       5.0   \n",
       "\n",
       "   coverage  coherence  overall  \\\n",
       "0       6.0        5.0      5.0   \n",
       "1       4.0        7.0      4.0   \n",
       "2       6.0        7.0      6.0   \n",
       "3       6.0        7.0      6.0   \n",
       "4       7.0        7.0      6.0   \n",
       "\n",
       "                                         ref_summary  m_rouge_1_f  \\\n",
       "0  infestation of scabies mites in apartment, roo...     0.173913   \n",
       "1  infestation of scabies mites in apartment, roo...     0.055556   \n",
       "2  infestation of scabies mites in apartment, roo...     0.232558   \n",
       "3  infestation of scabies mites in apartment, roo...     0.108108   \n",
       "4  infestation of scabies mites in apartment, roo...     0.190476   \n",
       "\n",
       "   m_rouge_2_f  m_rouge_l_f    m_bleu  m_flesch_reading_ease  \\\n",
       "0     0.000000     0.130435  0.006990                  87.92   \n",
       "1     0.000000     0.055556  0.007266                  78.93   \n",
       "2     0.040000     0.186047  0.014123                  70.63   \n",
       "3     0.000000     0.054054  0.009849                  73.51   \n",
       "4     0.044444     0.142857  0.016276                  89.45   \n",
       "\n",
       "   m_syllable_count  m_lexicon_count  m_sentence_count  m_char_count  \\\n",
       "0              46.0             35.0               4.0         150.0   \n",
       "1              31.0             26.0               1.0         110.0   \n",
       "2              50.0             35.0               2.0         158.0   \n",
       "3              30.0             23.0               1.0          90.0   \n",
       "4              38.0             29.0               4.0         123.0   \n",
       "\n",
       "   m_letter_count  m_polysyllab_count  m_monosyllab_count  \n",
       "0           144.0                 3.0                27.0  \n",
       "1           108.0                 1.0                22.0  \n",
       "2           155.0                 4.0                25.0  \n",
       "3            87.0                 2.0                18.0  \n",
       "4           117.0                 2.0                22.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_axis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-b3d106b07be1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m score(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_comparisons\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"summary_0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtrain_comparisons\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ref_summary\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bert_score\\score.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(cands, refs, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, lang, return_hash, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"calculating scores...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     all_preds = bert_cos_score_idf(\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mrefs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bert_score\\utils.py\u001b[0m in \u001b[0;36mbert_cos_score_idf\u001b[1;34m(model, refs, hyps, tokenizer, idf_dict, verbose, batch_size, device, all_layers)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdedup_and_sort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrefs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mhyps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m     \u001b[0membs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     \u001b[0miter_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bert_score\\utils.py\u001b[0m in \u001b[0;36mdedup_and_sort\u001b[1;34m(l)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdedup_and_sort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdedup_and_sort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrefs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mhyps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bert_score\\utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdedup_and_sort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdedup_and_sort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrefs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mhyps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "score(\n",
    "    train_comparisons[\"summary_0\"].iloc[:10000].tolist(),\n",
    "    train_comparisons[\"ref_summary\"].iloc[:10000].tolist(),\n",
    "    lang='en', verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 56.00 MiB (GPU 0; 6.00 GiB total capacity; 5.18 GiB already allocated; 0 bytes free; 5.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-6d5f65cae53a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbertscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bertscore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m bertscore.compute(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_comparisons\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"summary_0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mreferences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_comparisons\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ref_summary\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\evaluate\\module.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0minput_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minput_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtemp_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcompute_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuf_writer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--bertscore\\cf4907b18f8f741f202232c0f8009a3bd49ff98802c245abcb6ea51a37a8c05b\\bertscore.py\u001b[0m in \u001b[0;36m_compute\u001b[1;34m(self, predictions, references, lang, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[0;32m    201\u001b[0m                 )\n\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         (P, R, F) = self.cached_bertscorer.score(\n\u001b[0m\u001b[0;32m    204\u001b[0m             \u001b[0mcands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mrefs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreferences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bert_score\\scorer.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, cands, refs, verbose, batch_size, return_hash)\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[0midf_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcls_token_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         all_preds = bert_cos_score_idf(\n\u001b[0m\u001b[0;32m    221\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[0mrefs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bert_score\\utils.py\u001b[0m in \u001b[0;36mbert_cos_score_idf\u001b[1;34m(model, refs, hyps, tokenizer, idf_dict, verbose, batch_size, device, all_layers)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_start\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miter_range\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m         \u001b[0msen_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_start\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mbatch_start\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m         embs, masks, padded_idf = get_bert_embedding(\n\u001b[0m\u001b[0;32m    617\u001b[0m             \u001b[0msen_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midf_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bert_score\\utils.py\u001b[0m in \u001b[0;36mget_bert_embedding\u001b[1;34m(all_sens, model, tokenizer, idf_dict, batch_size, device, all_layers)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_sens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m             batch_embedding = bert_encode(\n\u001b[0m\u001b[0;32m    456\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m                 \u001b[0mpadded_sens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bert_score\\utils.py\u001b[0m in \u001b[0;36mbert_encode\u001b[1;34m(model, x, attention_mask, all_layers)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mall_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[0memb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    842\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m         )\n\u001b[1;32m--> 844\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    845\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    518\u001b[0m                 )\n\u001b[0;32m    519\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    521\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[0;32m    406\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[1;32m--> 332\u001b[1;33m         self_outputs = self.self(\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    250\u001b[0m                 \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrelative_position_scores_query\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrelative_position_scores_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[1;31m# Apply the attention mask is (precomputed for all layers in RobertaModel forward() function)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 56.00 MiB (GPU 0; 6.00 GiB total capacity; 5.18 GiB already allocated; 0 bytes free; 5.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")\n",
    "bertscore.compute(\n",
    "    predictions=train_comparisons[\"summary_0\"].iloc[:10000].tolist(), \n",
    "    references=train_comparisons[\"ref_summary\"].iloc[:10000].tolist(), \n",
    "    lang=\"en\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Mum is mad at me for not flying on my own trip...\n",
       "1    I have made sure my mother is comfortable with...\n",
       "2    mum isn't speaking to me because I booked a fl...\n",
       "3    Mum thought I was going to road trip with my b...\n",
       "4    My landlord is harassing me and my neighbours ...\n",
       "5    Landlord taped false message on door for every...\n",
       "6    landlord pretended to be another tenant and wr...\n",
       "7    landlord is a pathological liar who is now try...\n",
       "8    RA owes me money, made me buy her toys in a fu...\n",
       "9    RA verbally abused me and I want to get her to...\n",
       "Name: summary_0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comparisons[\"summary_0\"].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    mum isn't speaking to me because I booked a fl...\n",
       "1    mum isn't speaking to me because I booked a fl...\n",
       "2    mum isn't speaking to me because I booked a fl...\n",
       "3    mum isn't speaking to me because I booked a fl...\n",
       "4    landlord pretended to be another tenant and wr...\n",
       "5    landlord pretended to be another tenant and wr...\n",
       "6    landlord pretended to be another tenant and wr...\n",
       "7    landlord pretended to be another tenant and wr...\n",
       "8    My rude RA voluntarily participated in a fundr...\n",
       "9    My rude RA voluntarily participated in a fundr...\n",
       "Name: ref_summary, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comparisons[\"ref_summary\"].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction, corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge = Rouge()\n",
    "\n",
    "hyp_col = \"summary_0\"\n",
    "ref_col = \"ref_summary\"\n",
    "\n",
    "# Calculate BLEU scores for each row in the DataFrame\n",
    "scores = []\n",
    "for _, row in train_comparisons.iloc[:10000].iterrows():\n",
    "    if pd.notna(row[hyp_col]) and pd.notna(row[ref_col]):\n",
    "        score = sentence_bleu([row[ref_col].split()], row[hyp_col].split(), smoothing_function=SmoothingFunction().method1)\n",
    "        scores.append(score)\n",
    "    else:\n",
    "        scores.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05734547141000556,\n",
       " 0.046340057369294134,\n",
       " 1.0,\n",
       " 0.008724383945340666,\n",
       " 0.007511251053510192,\n",
       " 0.00644973654538667,\n",
       " 1.0,\n",
       " 0.05861484411000976,\n",
       " 0.023705266435224467,\n",
       " 0.015327272711566604,\n",
       " 1.0,\n",
       " 0.04595331932733298,\n",
       " 1.0,\n",
       " 0.0018635177896896655,\n",
       " 0.008186841244220632,\n",
       " 0.005043576168330867,\n",
       " 1.0,\n",
       " 0.02826536051832204,\n",
       " 0.018693000799960027,\n",
       " 0.024635236830568785,\n",
       " 0.013679192123121896,\n",
       " 0.0072658577559704465,\n",
       " 1.0,\n",
       " 0.011964983992380529,\n",
       " 1.0,\n",
       " 0,\n",
       " 0.01222498616281612,\n",
       " 0.0079451778602637,\n",
       " 0.014761667142304912,\n",
       " 0.005959978627465526,\n",
       " 0.009856825562461773,\n",
       " 1.0,\n",
       " 0.003764359569932285,\n",
       " 0.0053054184475599475,\n",
       " 1.0,\n",
       " 0.006244526986024011,\n",
       " 1.0,\n",
       " 0.008839374326825921,\n",
       " 0.008071364532479952,\n",
       " 0.006808256983563219,\n",
       " 1.0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.044430476392424055,\n",
       " 0.0015433589861169757,\n",
       " 0.005416537167077636,\n",
       " 1.0,\n",
       " 0.027948661656725198,\n",
       " 1.0,\n",
       " 3.197599924070407e-05,\n",
       " 0.0251383253456915,\n",
       " 0.0169861974906263,\n",
       " 0.004620856909230222,\n",
       " 0.053463162573637084,\n",
       " 1.0,\n",
       " 0.0041674709133537055,\n",
       " 1.0,\n",
       " 0.00497948402394365,\n",
       " 0.005214763215296812,\n",
       " 0.0041674709133537055,\n",
       " 1.0,\n",
       " 0.00497948402394365,\n",
       " 0.005214763215296812,\n",
       " 0.0041674709133537055,\n",
       " 1.0,\n",
       " 0.00497948402394365,\n",
       " 0.005214763215296812,\n",
       " 0.0041674709133537055,\n",
       " 1.0,\n",
       " 0.00497948402394365,\n",
       " 0.005214763215296812,\n",
       " 0.0041674709133537055,\n",
       " 1.0,\n",
       " 0.00497948402394365,\n",
       " 0.005214763215296812,\n",
       " 0.0041674709133537055,\n",
       " 1.0,\n",
       " 0.00497948402394365,\n",
       " 0.005214763215296812,\n",
       " 0.0041674709133537055,\n",
       " 1.0,\n",
       " 0.00497948402394365,\n",
       " 0.005214763215296812,\n",
       " 0.0041674709133537055,\n",
       " 1.0,\n",
       " 0.00497948402394365,\n",
       " 0.005214763215296812,\n",
       " 0.0041674709133537055,\n",
       " 1.0,\n",
       " 0.00497948402394365,\n",
       " 0.005214763215296812,\n",
       " 0.0041674709133537055,\n",
       " 1.0,\n",
       " 0.00497948402394365,\n",
       " 0.005214763215296812,\n",
       " 0.0041674709133537055,\n",
       " 1.0,\n",
       " 0.00497948402394365,\n",
       " 0.005214763215296812]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Someone alleges my GF assaulted her at a concert in Mississippi, from which she's flying back home today, which is total BS and she hit my GF first and even cop believes her. She is supposed to show up in court next week and plead her case, which is ridiculous\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[ref_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005214763215296812"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu([row[ref_col].split()], row[hyp_col].split(), smoothing_function=SmoothingFunction().method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.784451369270533e-232"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bleu([row[ref_col].split()], [row[hyp_col].split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-a5599f7152af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rouge-1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"f\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "score[\"rouge-1\"][\"f\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-094f82be6235>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m [\n\u001b[0m\u001b[0;32m      2\u001b[0m             \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rouge-1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"f\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         ]\n",
      "\u001b[1;32m<ipython-input-36-094f82be6235>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m [\n\u001b[1;32m----> 2\u001b[1;33m             \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rouge-1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"f\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         ]\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "[\n",
    "            score[\"rouge-1\"][\"f\"] if score is not None else None for score in scores\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>batch</th>\n",
       "      <th>split</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>subsource</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>summary_0</th>\n",
       "      <th>policy_0</th>\n",
       "      <th>...</th>\n",
       "      <th>note_1</th>\n",
       "      <th>confidence</th>\n",
       "      <th>choice</th>\n",
       "      <th>ref_summary</th>\n",
       "      <th>m0_rouge_1_f</th>\n",
       "      <th>m0_rouge_2_f</th>\n",
       "      <th>m0_rouge_l_f</th>\n",
       "      <th>m1_rouge_1_f</th>\n",
       "      <th>m1_rouge_2_f</th>\n",
       "      <th>m1_rouge_l_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_34xale</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>Mother  not speaking to me  because of a trip ...</td>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>Mum is mad at me for not flying on my own trip...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_34xale</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>Mother  not speaking to me  because of a trip ...</td>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>I have made sure my mother is comfortable with...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_34xale</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>Mother  not speaking to me  because of a trip ...</td>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>ref</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_34xale</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>Mother  not speaking to me  because of a trip ...</td>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>Mum thought I was going to road trip with my b...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LjvoXOAj5op3WqNnn5b7TZTG8mK7gM</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_1zwek5</td>\n",
       "      <td>reddit</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>Can I sue my property management company and l...</td>\n",
       "      <td>My landlord left a falsified message taped to ...</td>\n",
       "      <td>My landlord is harassing me and my neighbours ...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>landlord pretended to be another tenant and wr...</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92816</th>\n",
       "      <td>44Z8ttpKcY6Kr1sNymNnBA0nL0h4dZ</td>\n",
       "      <td>batch9</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_2n5vfw</td>\n",
       "      <td>reddit</td>\n",
       "      <td>tifu</td>\n",
       "      <td>TIFU by trying to get out of an assignment</td>\n",
       "      <td>So.. TIFU about fifteen minutes ago, when I wa...</td>\n",
       "      <td>Thought about trying to get out of work by bre...</td>\n",
       "      <td>ref</td>\n",
       "      <td>...</td>\n",
       "      <td>ok</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Thought about trying to get out of work by bre...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92817</th>\n",
       "      <td>44Z8ttpKcY6Kr1sNymNnBA0nL0h4dZ</td>\n",
       "      <td>batch9</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_2n5vfw</td>\n",
       "      <td>reddit</td>\n",
       "      <td>tifu</td>\n",
       "      <td>TIFU by trying to get out of an assignment</td>\n",
       "      <td>So.. TIFU about fifteen minutes ago, when I wa...</td>\n",
       "      <td>TIFU by accidentily spilling half a glass of w...</td>\n",
       "      <td>sup4_ppo_rm3_kl10</td>\n",
       "      <td>...</td>\n",
       "      <td>\"... my work is on Dropbox on all my spare tim...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thought about trying to get out of work by bre...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.326531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92818</th>\n",
       "      <td>44Z8ttpKcY6Kr1sNymNnBA0nL0h4dZ</td>\n",
       "      <td>batch9</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_2n5vfw</td>\n",
       "      <td>reddit</td>\n",
       "      <td>tifu</td>\n",
       "      <td>TIFU by trying to get out of an assignment</td>\n",
       "      <td>So.. TIFU about fifteen minutes ago, when I wa...</td>\n",
       "      <td>TIFU by trying to get out of an assignment by ...</td>\n",
       "      <td>sup4_ppo_rm3_kl10</td>\n",
       "      <td>...</td>\n",
       "      <td>ok</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Thought about trying to get out of work by bre...</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92819</th>\n",
       "      <td>44Z8ttpKcY6Kr1sNymNnBA0nL0h4dZ</td>\n",
       "      <td>batch9</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_2n5vfw</td>\n",
       "      <td>reddit</td>\n",
       "      <td>tifu</td>\n",
       "      <td>TIFU by trying to get out of an assignment</td>\n",
       "      <td>So.. TIFU about fifteen minutes ago, when I wa...</td>\n",
       "      <td>Thought about trying to get out of work by bre...</td>\n",
       "      <td>ref</td>\n",
       "      <td>...</td>\n",
       "      <td>strange</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Thought about trying to get out of work by bre...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92820</th>\n",
       "      <td>44Z8ttpKcY6Kr1sNymNnBA0nL0h4dZ</td>\n",
       "      <td>batch9</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_2n5vfw</td>\n",
       "      <td>reddit</td>\n",
       "      <td>tifu</td>\n",
       "      <td>TIFU by trying to get out of an assignment</td>\n",
       "      <td>So.. TIFU about fifteen minutes ago, when I wa...</td>\n",
       "      <td>TIFU by accidentily spilling half a glass of w...</td>\n",
       "      <td>sup4_ppo_rm3_kl10</td>\n",
       "      <td>...</td>\n",
       "      <td>ok</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Thought about trying to get out of work by bre...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92821 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               worker   batch  split         id  source  \\\n",
       "0      qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  batch3  train  t3_34xale  reddit   \n",
       "1      qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  batch3  train  t3_34xale  reddit   \n",
       "2      qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  batch3  train  t3_34xale  reddit   \n",
       "3      qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  batch3  train  t3_34xale  reddit   \n",
       "4      LjvoXOAj5op3WqNnn5b7TZTG8mK7gM  batch3  train  t3_1zwek5  reddit   \n",
       "...                               ...     ...    ...        ...     ...   \n",
       "92816  44Z8ttpKcY6Kr1sNymNnBA0nL0h4dZ  batch9  train  t3_2n5vfw  reddit   \n",
       "92817  44Z8ttpKcY6Kr1sNymNnBA0nL0h4dZ  batch9  train  t3_2n5vfw  reddit   \n",
       "92818  44Z8ttpKcY6Kr1sNymNnBA0nL0h4dZ  batch9  train  t3_2n5vfw  reddit   \n",
       "92819  44Z8ttpKcY6Kr1sNymNnBA0nL0h4dZ  batch9  train  t3_2n5vfw  reddit   \n",
       "92820  44Z8ttpKcY6Kr1sNymNnBA0nL0h4dZ  batch9  train  t3_2n5vfw  reddit   \n",
       "\n",
       "           subsource                                              title  \\\n",
       "0      relationships  Mother  not speaking to me  because of a trip ...   \n",
       "1      relationships  Mother  not speaking to me  because of a trip ...   \n",
       "2      relationships  Mother  not speaking to me  because of a trip ...   \n",
       "3      relationships  Mother  not speaking to me  because of a trip ...   \n",
       "4          AskReddit  Can I sue my property management company and l...   \n",
       "...              ...                                                ...   \n",
       "92816           tifu         TIFU by trying to get out of an assignment   \n",
       "92817           tifu         TIFU by trying to get out of an assignment   \n",
       "92818           tifu         TIFU by trying to get out of an assignment   \n",
       "92819           tifu         TIFU by trying to get out of an assignment   \n",
       "92820           tifu         TIFU by trying to get out of an assignment   \n",
       "\n",
       "                                                    text  \\\n",
       "0      My boyfriend and I are long distance. We have ...   \n",
       "1      My boyfriend and I are long distance. We have ...   \n",
       "2      My boyfriend and I are long distance. We have ...   \n",
       "3      My boyfriend and I are long distance. We have ...   \n",
       "4      My landlord left a falsified message taped to ...   \n",
       "...                                                  ...   \n",
       "92816  So.. TIFU about fifteen minutes ago, when I wa...   \n",
       "92817  So.. TIFU about fifteen minutes ago, when I wa...   \n",
       "92818  So.. TIFU about fifteen minutes ago, when I wa...   \n",
       "92819  So.. TIFU about fifteen minutes ago, when I wa...   \n",
       "92820  So.. TIFU about fifteen minutes ago, when I wa...   \n",
       "\n",
       "                                               summary_0           policy_0  \\\n",
       "0      Mum is mad at me for not flying on my own trip...               sup1   \n",
       "1      I have made sure my mother is comfortable with...               sup1   \n",
       "2      mum isn't speaking to me because I booked a fl...                ref   \n",
       "3      Mum thought I was going to road trip with my b...               sup1   \n",
       "4      My landlord is harassing me and my neighbours ...               sup1   \n",
       "...                                                  ...                ...   \n",
       "92816  Thought about trying to get out of work by bre...                ref   \n",
       "92817  TIFU by accidentily spilling half a glass of w...  sup4_ppo_rm3_kl10   \n",
       "92818  TIFU by trying to get out of an assignment by ...  sup4_ppo_rm3_kl10   \n",
       "92819  Thought about trying to get out of work by bre...                ref   \n",
       "92820  TIFU by accidentily spilling half a glass of w...  sup4_ppo_rm3_kl10   \n",
       "\n",
       "       ...                                             note_1 confidence  \\\n",
       "0      ...                                                NaN        NaN   \n",
       "1      ...                                                NaN        NaN   \n",
       "2      ...                                                NaN        NaN   \n",
       "3      ...                                                NaN        NaN   \n",
       "4      ...                                                NaN        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "92816  ...                                                 ok        9.0   \n",
       "92817  ...  \"... my work is on Dropbox on all my spare tim...        3.0   \n",
       "92818  ...                                                 ok        9.0   \n",
       "92819  ...                                            strange        7.0   \n",
       "92820  ...                                                 ok        9.0   \n",
       "\n",
       "      choice                                        ref_summary  m0_rouge_1_f  \\\n",
       "0          1  mum isn't speaking to me because I booked a fl...      0.363636   \n",
       "1          1  mum isn't speaking to me because I booked a fl...      0.368421   \n",
       "2          0  mum isn't speaking to me because I booked a fl...      1.000000   \n",
       "3          0  mum isn't speaking to me because I booked a fl...      0.325581   \n",
       "4          1  landlord pretended to be another tenant and wr...      0.137931   \n",
       "...      ...                                                ...           ...   \n",
       "92816      1  Thought about trying to get out of work by bre...      1.000000   \n",
       "92817      0  Thought about trying to get out of work by bre...      0.250000   \n",
       "92818      1  Thought about trying to get out of work by bre...      0.367347   \n",
       "92819      1  Thought about trying to get out of work by bre...      1.000000   \n",
       "92820      1  Thought about trying to get out of work by bre...      0.250000   \n",
       "\n",
       "       m0_rouge_2_f m0_rouge_l_f  m1_rouge_1_f  m1_rouge_2_f  m1_rouge_l_f  \n",
       "0          0.181818     0.303030      0.368421      0.100000      0.210526  \n",
       "1          0.100000     0.210526      1.000000      1.000000      1.000000  \n",
       "2          1.000000     1.000000      0.325581      0.000000      0.279070  \n",
       "3          0.000000     0.279070      0.363636      0.181818      0.303030  \n",
       "4          0.000000     0.137931      1.000000      1.000000      1.000000  \n",
       "...             ...          ...           ...           ...           ...  \n",
       "92816      1.000000     1.000000      0.326531      0.166667      0.285714  \n",
       "92817      0.033333     0.142857      0.367347      0.142857      0.326531  \n",
       "92818      0.142857     0.326531      0.326531      0.166667      0.285714  \n",
       "92819      1.000000     1.000000      0.250000      0.033333      0.142857  \n",
       "92820      0.033333     0.142857      0.326531      0.166667      0.285714  \n",
       "\n",
       "[92821 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>batch</th>\n",
       "      <th>split</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>subsource</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>policy</th>\n",
       "      <th>note</th>\n",
       "      <th>compatible</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>coverage</th>\n",
       "      <th>coherence</th>\n",
       "      <th>overall</th>\n",
       "      <th>ref_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>cnndm1</td>\n",
       "      <td>test</td>\n",
       "      <td>167f80cc6634b166a699d182e25c81a2349d82d2</td>\n",
       "      <td>cnn_dailymail</td>\n",
       "      <td>dailymail</td>\n",
       "      <td>Newcastle United midfielder Moussa Sissoko fac...</td>\n",
       "      <td>Newcastle stand-in skipper Moussa Sissoko is f...</td>\n",
       "      <td>Moussa Sissoko was sent off against Liverpool ...</td>\n",
       "      <td>ref</td>\n",
       "      <td>Misleading: \"Carver admits he is only concerne...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moussa Sissoko was sent off against Liverpool ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>cnndm1</td>\n",
       "      <td>test</td>\n",
       "      <td>167f80cc6634b166a699d182e25c81a2349d82d2</td>\n",
       "      <td>cnn_dailymail</td>\n",
       "      <td>dailymail</td>\n",
       "      <td>Newcastle United midfielder Moussa Sissoko fac...</td>\n",
       "      <td>Newcastle stand-in skipper Moussa Sissoko is f...</td>\n",
       "      <td>Newcastle have a mountain to climb in the Prem...</td>\n",
       "      <td>sup4_t0.7</td>\n",
       "      <td>\"Carver is determined to make the most of his ...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Moussa Sissoko was sent off against Liverpool ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>cnndm1</td>\n",
       "      <td>test</td>\n",
       "      <td>167f80cc6634b166a699d182e25c81a2349d82d2</td>\n",
       "      <td>cnn_dailymail</td>\n",
       "      <td>dailymail</td>\n",
       "      <td>Newcastle United midfielder Moussa Sissoko fac...</td>\n",
       "      <td>Newcastle stand-in skipper Moussa Sissoko is f...</td>\n",
       "      <td>Moussa Sissoko has been sent off following a d...</td>\n",
       "      <td>sup4_ppo_rm4_t.7</td>\n",
       "      <td>\"Carver feels the player should have been sent...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Moussa Sissoko was sent off against Liverpool ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>cnndm1</td>\n",
       "      <td>test</td>\n",
       "      <td>167f80cc6634b166a699d182e25c81a2349d82d2</td>\n",
       "      <td>cnn_dailymail</td>\n",
       "      <td>dailymail</td>\n",
       "      <td>Newcastle United midfielder Moussa Sissoko fac...</td>\n",
       "      <td>Newcastle stand-in skipper Moussa Sissoko is f...</td>\n",
       "      <td>Moussa Sissoko is facing a disciplinary action...</td>\n",
       "      <td>pretrain_xl_t.7</td>\n",
       "      <td>Doesnt summarize important points. Match info ...</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moussa Sissoko was sent off against Liverpool ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>cnndm1</td>\n",
       "      <td>test</td>\n",
       "      <td>167f80cc6634b166a699d182e25c81a2349d82d2</td>\n",
       "      <td>cnn_dailymail</td>\n",
       "      <td>dailymail</td>\n",
       "      <td>Newcastle United midfielder Moussa Sissoko fac...</td>\n",
       "      <td>Newcastle stand-in skipper Moussa Sissoko is f...</td>\n",
       "      <td>Newcastle need to start helping themselves now...</td>\n",
       "      <td>sup4_6b_t0.7</td>\n",
       "      <td>Completely misses main info.</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Moussa Sissoko was sent off against Liverpool ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6286</th>\n",
       "      <td>uvzut5OK2bvei9zoCDdktcfLENYioY</td>\n",
       "      <td>cnndm4</td>\n",
       "      <td>test</td>\n",
       "      <td>843f85685d2ca5bab950e30d6cd89e91bc539018</td>\n",
       "      <td>cnn_dailymail</td>\n",
       "      <td>dailymail</td>\n",
       "      <td>Lamb born twice the normal size weighing 20lbs...</td>\n",
       "      <td>This bundle of joy was a special spring surpri...</td>\n",
       "      <td>This bundle of joy was a special spring surpri...</td>\n",
       "      <td>lead3</td>\n",
       "      <td>â€¢great summary with elaborate detail.</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Farmers named him Big Ben as he dwarfs other 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6287</th>\n",
       "      <td>uvzut5OK2bvei9zoCDdktcfLENYioY</td>\n",
       "      <td>cnndm4</td>\n",
       "      <td>test</td>\n",
       "      <td>843f85685d2ca5bab950e30d6cd89e91bc539018</td>\n",
       "      <td>cnn_dailymail</td>\n",
       "      <td>dailymail</td>\n",
       "      <td>Lamb born twice the normal size weighing 20lbs...</td>\n",
       "      <td>This bundle of joy was a special spring surpri...</td>\n",
       "      <td>Big Ben is twice the weight of the average new...</td>\n",
       "      <td>supcnndm1_6b</td>\n",
       "      <td>â€¢[He is the biggest lamb ever born in the UK.]...</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Farmers named him Big Ben as he dwarfs other 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6288</th>\n",
       "      <td>uvzut5OK2bvei9zoCDdktcfLENYioY</td>\n",
       "      <td>cnndm4</td>\n",
       "      <td>test</td>\n",
       "      <td>843f85685d2ca5bab950e30d6cd89e91bc539018</td>\n",
       "      <td>cnn_dailymail</td>\n",
       "      <td>dailymail</td>\n",
       "      <td>Lamb born twice the normal size weighing 20lbs...</td>\n",
       "      <td>This bundle of joy was a special spring surpri...</td>\n",
       "      <td>Shepherd John Hendy and team of three helpers ...</td>\n",
       "      <td>supcnndm3_6b</td>\n",
       "      <td>â€¢sufficient key information but minimal details.</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Farmers named him Big Ben as he dwarfs other 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6289</th>\n",
       "      <td>uvzut5OK2bvei9zoCDdktcfLENYioY</td>\n",
       "      <td>cnndm4</td>\n",
       "      <td>test</td>\n",
       "      <td>843f85685d2ca5bab950e30d6cd89e91bc539018</td>\n",
       "      <td>cnn_dailymail</td>\n",
       "      <td>dailymail</td>\n",
       "      <td>Lamb born twice the normal size weighing 20lbs...</td>\n",
       "      <td>This bundle of joy was a special spring surpri...</td>\n",
       "      <td>This bundle of joy was a special spring surpri...</td>\n",
       "      <td>pretrain_xl</td>\n",
       "      <td>â€¢good summary with average detail.</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Farmers named him Big Ben as he dwarfs other 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>uvzut5OK2bvei9zoCDdktcfLENYioY</td>\n",
       "      <td>cnndm4</td>\n",
       "      <td>test</td>\n",
       "      <td>843f85685d2ca5bab950e30d6cd89e91bc539018</td>\n",
       "      <td>cnn_dailymail</td>\n",
       "      <td>dailymail</td>\n",
       "      <td>Lamb born twice the normal size weighing 20lbs...</td>\n",
       "      <td>This bundle of joy was a special spring surpri...</td>\n",
       "      <td>Suffolk lamb born weighing 20lbs is the bigges...</td>\n",
       "      <td>sup4_6b_ppo_rm4_6b</td>\n",
       "      <td>â€¢good summary with average detail.</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Farmers named him Big Ben as he dwarfs other 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6291 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              worker   batch split  \\\n",
       "0     qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  cnndm1  test   \n",
       "1     qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  cnndm1  test   \n",
       "2     qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  cnndm1  test   \n",
       "3     qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  cnndm1  test   \n",
       "4     qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  cnndm1  test   \n",
       "...                              ...     ...   ...   \n",
       "6286  uvzut5OK2bvei9zoCDdktcfLENYioY  cnndm4  test   \n",
       "6287  uvzut5OK2bvei9zoCDdktcfLENYioY  cnndm4  test   \n",
       "6288  uvzut5OK2bvei9zoCDdktcfLENYioY  cnndm4  test   \n",
       "6289  uvzut5OK2bvei9zoCDdktcfLENYioY  cnndm4  test   \n",
       "6290  uvzut5OK2bvei9zoCDdktcfLENYioY  cnndm4  test   \n",
       "\n",
       "                                            id         source  subsource  \\\n",
       "0     167f80cc6634b166a699d182e25c81a2349d82d2  cnn_dailymail  dailymail   \n",
       "1     167f80cc6634b166a699d182e25c81a2349d82d2  cnn_dailymail  dailymail   \n",
       "2     167f80cc6634b166a699d182e25c81a2349d82d2  cnn_dailymail  dailymail   \n",
       "3     167f80cc6634b166a699d182e25c81a2349d82d2  cnn_dailymail  dailymail   \n",
       "4     167f80cc6634b166a699d182e25c81a2349d82d2  cnn_dailymail  dailymail   \n",
       "...                                        ...            ...        ...   \n",
       "6286  843f85685d2ca5bab950e30d6cd89e91bc539018  cnn_dailymail  dailymail   \n",
       "6287  843f85685d2ca5bab950e30d6cd89e91bc539018  cnn_dailymail  dailymail   \n",
       "6288  843f85685d2ca5bab950e30d6cd89e91bc539018  cnn_dailymail  dailymail   \n",
       "6289  843f85685d2ca5bab950e30d6cd89e91bc539018  cnn_dailymail  dailymail   \n",
       "6290  843f85685d2ca5bab950e30d6cd89e91bc539018  cnn_dailymail  dailymail   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Newcastle United midfielder Moussa Sissoko fac...   \n",
       "1     Newcastle United midfielder Moussa Sissoko fac...   \n",
       "2     Newcastle United midfielder Moussa Sissoko fac...   \n",
       "3     Newcastle United midfielder Moussa Sissoko fac...   \n",
       "4     Newcastle United midfielder Moussa Sissoko fac...   \n",
       "...                                                 ...   \n",
       "6286  Lamb born twice the normal size weighing 20lbs...   \n",
       "6287  Lamb born twice the normal size weighing 20lbs...   \n",
       "6288  Lamb born twice the normal size weighing 20lbs...   \n",
       "6289  Lamb born twice the normal size weighing 20lbs...   \n",
       "6290  Lamb born twice the normal size weighing 20lbs...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     Newcastle stand-in skipper Moussa Sissoko is f...   \n",
       "1     Newcastle stand-in skipper Moussa Sissoko is f...   \n",
       "2     Newcastle stand-in skipper Moussa Sissoko is f...   \n",
       "3     Newcastle stand-in skipper Moussa Sissoko is f...   \n",
       "4     Newcastle stand-in skipper Moussa Sissoko is f...   \n",
       "...                                                 ...   \n",
       "6286  This bundle of joy was a special spring surpri...   \n",
       "6287  This bundle of joy was a special spring surpri...   \n",
       "6288  This bundle of joy was a special spring surpri...   \n",
       "6289  This bundle of joy was a special spring surpri...   \n",
       "6290  This bundle of joy was a special spring surpri...   \n",
       "\n",
       "                                                summary              policy  \\\n",
       "0     Moussa Sissoko was sent off against Liverpool ...                 ref   \n",
       "1     Newcastle have a mountain to climb in the Prem...           sup4_t0.7   \n",
       "2     Moussa Sissoko has been sent off following a d...    sup4_ppo_rm4_t.7   \n",
       "3     Moussa Sissoko is facing a disciplinary action...     pretrain_xl_t.7   \n",
       "4     Newcastle need to start helping themselves now...        sup4_6b_t0.7   \n",
       "...                                                 ...                 ...   \n",
       "6286  This bundle of joy was a special spring surpri...               lead3   \n",
       "6287  Big Ben is twice the weight of the average new...        supcnndm1_6b   \n",
       "6288  Shepherd John Hendy and team of three helpers ...        supcnndm3_6b   \n",
       "6289  This bundle of joy was a special spring surpri...         pretrain_xl   \n",
       "6290  Suffolk lamb born weighing 20lbs is the bigges...  sup4_6b_ppo_rm4_6b   \n",
       "\n",
       "                                                   note  compatible  accuracy  \\\n",
       "0     Misleading: \"Carver admits he is only concerne...       False         5   \n",
       "1     \"Carver is determined to make the most of his ...       False         3   \n",
       "2     \"Carver feels the player should have been sent...       False         4   \n",
       "3     Doesnt summarize important points. Match info ...       False         7   \n",
       "4                          Completely misses main info.       False         7   \n",
       "...                                                 ...         ...       ...   \n",
       "6286              â€¢great summary with elaborate detail.        True         7   \n",
       "6287  â€¢[He is the biggest lamb ever born in the UK.]...        True         4   \n",
       "6288   â€¢sufficient key information but minimal details.        True         7   \n",
       "6289                 â€¢good summary with average detail.        True         7   \n",
       "6290                 â€¢good summary with average detail.        True         7   \n",
       "\n",
       "      coverage  coherence  overall  \\\n",
       "0            4        2.0        3   \n",
       "1            1        1.0        1   \n",
       "2            2        2.0        2   \n",
       "3            3        6.0        3   \n",
       "4            1        3.0        1   \n",
       "...        ...        ...      ...   \n",
       "6286         7        7.0        7   \n",
       "6287         5        7.0        4   \n",
       "6288         5        7.0        4   \n",
       "6289         6        7.0        6   \n",
       "6290         6        7.0        7   \n",
       "\n",
       "                                            ref_summary  \n",
       "0     Moussa Sissoko was sent off against Liverpool ...  \n",
       "1     Moussa Sissoko was sent off against Liverpool ...  \n",
       "2     Moussa Sissoko was sent off against Liverpool ...  \n",
       "3     Moussa Sissoko was sent off against Liverpool ...  \n",
       "4     Moussa Sissoko was sent off against Liverpool ...  \n",
       "...                                                 ...  \n",
       "6286  Farmers named him Big Ben as he dwarfs other 8...  \n",
       "6287  Farmers named him Big Ben as he dwarfs other 8...  \n",
       "6288  Farmers named him Big Ben as he dwarfs other 8...  \n",
       "6289  Farmers named him Big Ben as he dwarfs other 8...  \n",
       "6290  Farmers named him Big Ben as he dwarfs other 8...  \n",
       "\n",
       "[6291 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>batch</th>\n",
       "      <th>split</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>subsource</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>policy</th>\n",
       "      <th>note</th>\n",
       "      <th>compatible</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>coverage</th>\n",
       "      <th>coherence</th>\n",
       "      <th>overall</th>\n",
       "      <th>ref_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iL7GfrbN2PeB3KInidqSxUdxYcTZmG</td>\n",
       "      <td>tldraxis1</td>\n",
       "      <td>valid2</td>\n",
       "      <td>t3_4l0bal</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>19f with fiance 20m and roommate 19m- fiance a...</td>\n",
       "      <td>Recently, my fiance  (20 m) and I (19f) moved ...</td>\n",
       "      <td>Fiance and I recently got infected with scabie...</td>\n",
       "      <td>sup4_ppo_rm4_t.7</td>\n",
       "      <td>'our apartment will not go away. I'm afraid he...</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>infestation of scabies mites in apartment, roo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iL7GfrbN2PeB3KInidqSxUdxYcTZmG</td>\n",
       "      <td>tldraxis1</td>\n",
       "      <td>valid2</td>\n",
       "      <td>t3_4l0bal</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>19f with fiance 20m and roommate 19m- fiance a...</td>\n",
       "      <td>Recently, my fiance  (20 m) and I (19f) moved ...</td>\n",
       "      <td>my fiance and I refuse to treat our room mate'...</td>\n",
       "      <td>pretrain_6b_t.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>infestation of scabies mites in apartment, roo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iL7GfrbN2PeB3KInidqSxUdxYcTZmG</td>\n",
       "      <td>tldraxis1</td>\n",
       "      <td>valid2</td>\n",
       "      <td>t3_4l0bal</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>19f with fiance 20m and roommate 19m- fiance a...</td>\n",
       "      <td>Recently, my fiance  (20 m) and I (19f) moved ...</td>\n",
       "      <td>fiancÃ© and I contracted scabies, roommate refu...</td>\n",
       "      <td>sup4_6b_ppo_rm4_6b_t.7</td>\n",
       "      <td>the question s missing but the summary is good</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>infestation of scabies mites in apartment, roo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iL7GfrbN2PeB3KInidqSxUdxYcTZmG</td>\n",
       "      <td>tldraxis1</td>\n",
       "      <td>valid2</td>\n",
       "      <td>t3_4l0bal</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>19f with fiance 20m and roommate 19m- fiance a...</td>\n",
       "      <td>Recently, my fiance  (20 m) and I (19f) moved ...</td>\n",
       "      <td>fiance and I are infected with scabies, room m...</td>\n",
       "      <td>sup4_6b_t0.7</td>\n",
       "      <td>a small inaccuracy and omission, otherwise good</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>infestation of scabies mites in apartment, roo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iL7GfrbN2PeB3KInidqSxUdxYcTZmG</td>\n",
       "      <td>tldraxis1</td>\n",
       "      <td>valid2</td>\n",
       "      <td>t3_4l0bal</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>19f with fiance 20m and roommate 19m- fiance a...</td>\n",
       "      <td>Recently, my fiance  (20 m) and I (19f) moved ...</td>\n",
       "      <td>Fiance and I contracted scabies, roommate refu...</td>\n",
       "      <td>sup4_12b_t0.7</td>\n",
       "      <td>a small inaccuracy, otherwise good</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>infestation of scabies mites in apartment, roo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8580</th>\n",
       "      <td>uvzut5OK2bvei9zoCDdktcfLENYioY</td>\n",
       "      <td>tldraxis2</td>\n",
       "      <td>valid2</td>\n",
       "      <td>t3_3i230d</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>[Update 2] I [18 M] want to ask out a girl [18...</td>\n",
       "      <td>[Original](\\n(Clarification on this one, I did...</td>\n",
       "      <td>I want to ask out a girl on a date, general ti...</td>\n",
       "      <td>sup4_12b</td>\n",
       "      <td>â€¢summary has added info.</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Girl ignored me again, I cease conversation. H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581</th>\n",
       "      <td>uvzut5OK2bvei9zoCDdktcfLENYioY</td>\n",
       "      <td>tldraxis2</td>\n",
       "      <td>valid2</td>\n",
       "      <td>t3_3i230d</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>[Update 2] I [18 M] want to ask out a girl [18...</td>\n",
       "      <td>[Original](\\n(Clarification on this one, I did...</td>\n",
       "      <td>Girl ignored me again, I cease conversation. H...</td>\n",
       "      <td>ref</td>\n",
       "      <td>â€¢summary is completely made up.</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Girl ignored me again, I cease conversation. H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8582</th>\n",
       "      <td>uvzut5OK2bvei9zoCDdktcfLENYioY</td>\n",
       "      <td>tldraxis2</td>\n",
       "      <td>valid2</td>\n",
       "      <td>t3_3i230d</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>[Update 2] I [18 M] want to ask out a girl [18...</td>\n",
       "      <td>[Original](\\n(Clarification on this one, I did...</td>\n",
       "      <td>[Update 2] I [18 M] want to ask out a girl [18...</td>\n",
       "      <td>title</td>\n",
       "      <td>â€¢complete summary.</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Girl ignored me again, I cease conversation. H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8583</th>\n",
       "      <td>uvzut5OK2bvei9zoCDdktcfLENYioY</td>\n",
       "      <td>tldraxis2</td>\n",
       "      <td>valid2</td>\n",
       "      <td>t3_3i230d</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>[Update 2] I [18 M] want to ask out a girl [18...</td>\n",
       "      <td>[Original](\\n(Clarification on this one, I did...</td>\n",
       "      <td>[Original](\\n(Clarification on this one, I did...</td>\n",
       "      <td>lead2</td>\n",
       "      <td>â€¢summary is just an introduction from the orig...</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Girl ignored me again, I cease conversation. H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8584</th>\n",
       "      <td>uvzut5OK2bvei9zoCDdktcfLENYioY</td>\n",
       "      <td>tldraxis2</td>\n",
       "      <td>valid2</td>\n",
       "      <td>t3_3i230d</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>[Update 2] I [18 M] want to ask out a girl [18...</td>\n",
       "      <td>[Original](\\n(Clarification on this one, I did...</td>\n",
       "      <td>I want to ask out a girl on a date, general ti...</td>\n",
       "      <td>sup4_6b_ppo_rm4_6b</td>\n",
       "      <td>â€¢complete summary but has added information.</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Girl ignored me again, I cease conversation. H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8585 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              worker      batch   split         id  source  \\\n",
       "0     iL7GfrbN2PeB3KInidqSxUdxYcTZmG  tldraxis1  valid2  t3_4l0bal  reddit   \n",
       "1     iL7GfrbN2PeB3KInidqSxUdxYcTZmG  tldraxis1  valid2  t3_4l0bal  reddit   \n",
       "2     iL7GfrbN2PeB3KInidqSxUdxYcTZmG  tldraxis1  valid2  t3_4l0bal  reddit   \n",
       "3     iL7GfrbN2PeB3KInidqSxUdxYcTZmG  tldraxis1  valid2  t3_4l0bal  reddit   \n",
       "4     iL7GfrbN2PeB3KInidqSxUdxYcTZmG  tldraxis1  valid2  t3_4l0bal  reddit   \n",
       "...                              ...        ...     ...        ...     ...   \n",
       "8580  uvzut5OK2bvei9zoCDdktcfLENYioY  tldraxis2  valid2  t3_3i230d  reddit   \n",
       "8581  uvzut5OK2bvei9zoCDdktcfLENYioY  tldraxis2  valid2  t3_3i230d  reddit   \n",
       "8582  uvzut5OK2bvei9zoCDdktcfLENYioY  tldraxis2  valid2  t3_3i230d  reddit   \n",
       "8583  uvzut5OK2bvei9zoCDdktcfLENYioY  tldraxis2  valid2  t3_3i230d  reddit   \n",
       "8584  uvzut5OK2bvei9zoCDdktcfLENYioY  tldraxis2  valid2  t3_3i230d  reddit   \n",
       "\n",
       "                subsource                                              title  \\\n",
       "0     relationship_advice  19f with fiance 20m and roommate 19m- fiance a...   \n",
       "1     relationship_advice  19f with fiance 20m and roommate 19m- fiance a...   \n",
       "2     relationship_advice  19f with fiance 20m and roommate 19m- fiance a...   \n",
       "3     relationship_advice  19f with fiance 20m and roommate 19m- fiance a...   \n",
       "4     relationship_advice  19f with fiance 20m and roommate 19m- fiance a...   \n",
       "...                   ...                                                ...   \n",
       "8580        relationships  [Update 2] I [18 M] want to ask out a girl [18...   \n",
       "8581        relationships  [Update 2] I [18 M] want to ask out a girl [18...   \n",
       "8582        relationships  [Update 2] I [18 M] want to ask out a girl [18...   \n",
       "8583        relationships  [Update 2] I [18 M] want to ask out a girl [18...   \n",
       "8584        relationships  [Update 2] I [18 M] want to ask out a girl [18...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     Recently, my fiance  (20 m) and I (19f) moved ...   \n",
       "1     Recently, my fiance  (20 m) and I (19f) moved ...   \n",
       "2     Recently, my fiance  (20 m) and I (19f) moved ...   \n",
       "3     Recently, my fiance  (20 m) and I (19f) moved ...   \n",
       "4     Recently, my fiance  (20 m) and I (19f) moved ...   \n",
       "...                                                 ...   \n",
       "8580  [Original](\\n(Clarification on this one, I did...   \n",
       "8581  [Original](\\n(Clarification on this one, I did...   \n",
       "8582  [Original](\\n(Clarification on this one, I did...   \n",
       "8583  [Original](\\n(Clarification on this one, I did...   \n",
       "8584  [Original](\\n(Clarification on this one, I did...   \n",
       "\n",
       "                                                summary  \\\n",
       "0     Fiance and I recently got infected with scabie...   \n",
       "1     my fiance and I refuse to treat our room mate'...   \n",
       "2     fiancÃ© and I contracted scabies, roommate refu...   \n",
       "3     fiance and I are infected with scabies, room m...   \n",
       "4     Fiance and I contracted scabies, roommate refu...   \n",
       "...                                                 ...   \n",
       "8580  I want to ask out a girl on a date, general ti...   \n",
       "8581  Girl ignored me again, I cease conversation. H...   \n",
       "8582  [Update 2] I [18 M] want to ask out a girl [18...   \n",
       "8583  [Original](\\n(Clarification on this one, I did...   \n",
       "8584  I want to ask out a girl on a date, general ti...   \n",
       "\n",
       "                      policy  \\\n",
       "0           sup4_ppo_rm4_t.7   \n",
       "1            pretrain_6b_t.7   \n",
       "2     sup4_6b_ppo_rm4_6b_t.7   \n",
       "3               sup4_6b_t0.7   \n",
       "4              sup4_12b_t0.7   \n",
       "...                      ...   \n",
       "8580                sup4_12b   \n",
       "8581                     ref   \n",
       "8582                   title   \n",
       "8583                   lead2   \n",
       "8584      sup4_6b_ppo_rm4_6b   \n",
       "\n",
       "                                                   note  compatible  accuracy  \\\n",
       "0     'our apartment will not go away. I'm afraid he...       False       5.0   \n",
       "1                                                   NaN       False       4.0   \n",
       "2        the question s missing but the summary is good       False       6.0   \n",
       "3       a small inaccuracy and omission, otherwise good       False       6.0   \n",
       "4                    a small inaccuracy, otherwise good       False       5.0   \n",
       "...                                                 ...         ...       ...   \n",
       "8580                           â€¢summary has added info.        True       5.0   \n",
       "8581                    â€¢summary is completely made up.        True       1.0   \n",
       "8582                                 â€¢complete summary.        True       7.0   \n",
       "8583  â€¢summary is just an introduction from the orig...        True       7.0   \n",
       "8584       â€¢complete summary but has added information.        True       5.0   \n",
       "\n",
       "      coverage  coherence  overall  \\\n",
       "0          6.0        5.0      5.0   \n",
       "1          4.0        7.0      4.0   \n",
       "2          6.0        7.0      6.0   \n",
       "3          6.0        7.0      6.0   \n",
       "4          7.0        7.0      6.0   \n",
       "...        ...        ...      ...   \n",
       "8580       7.0        7.0      6.0   \n",
       "8581       1.0        7.0      1.0   \n",
       "8582       7.0        7.0      7.0   \n",
       "8583       1.0        7.0      1.0   \n",
       "8584       7.0        7.0      7.0   \n",
       "\n",
       "                                            ref_summary  \n",
       "0     infestation of scabies mites in apartment, roo...  \n",
       "1     infestation of scabies mites in apartment, roo...  \n",
       "2     infestation of scabies mites in apartment, roo...  \n",
       "3     infestation of scabies mites in apartment, roo...  \n",
       "4     infestation of scabies mites in apartment, roo...  \n",
       "...                                                 ...  \n",
       "8580  Girl ignored me again, I cease conversation. H...  \n",
       "8581  Girl ignored me again, I cease conversation. H...  \n",
       "8582  Girl ignored me again, I cease conversation. H...  \n",
       "8583  Girl ignored me again, I cease conversation. H...  \n",
       "8584  Girl ignored me again, I cease conversation. H...  \n",
       "\n",
       "[8585 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "def compute_rouge_scores(data: pd.DataFrame, hyp_col: str, ref_col: str, name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute ROUGE score.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df = data.copy()\n",
    "    \n",
    "    # Initialize ROUGE scorer\n",
    "    rouge = Rouge()\n",
    "    \n",
    "    # Calculate ROUGE scores for each row in the DataFrame\n",
    "    scores = []\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.notna(row[hyp_col]) and pd.notna(row[ref_col]):\n",
    "            score = rouge.get_scores(row[hyp_col], row[ref_col], avg=True)\n",
    "            scores.append(score)\n",
    "        else:\n",
    "            scores.append(None)\n",
    "\n",
    "    # Extract ROUGE-1, ROUGE-2, and ROUGE-L scores\n",
    "    df.loc[:, f\"{name}_rouge_1_f\"] = [\n",
    "        score[\"rouge-1\"][\"f\"] if score is not None else None for score in scores\n",
    "    ]\n",
    "    df.loc[:, f\"{name}_rouge_2_f\"] = [\n",
    "        score[\"rouge-2\"][\"f\"] if score is not None else None for score in scores\n",
    "    ]\n",
    "    df.loc[:, f\"{name}_rouge_l_f\"] = [\n",
    "        score[\"rouge-l\"][\"f\"] if score is not None else None for score in scores\n",
    "    ]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ROUGE scorer\n",
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.3888888888888889, 'p': 0.35, 'f': 0.3684210476454294},\n",
       "  'rouge-2': {'r': 0.1111111111111111,\n",
       "   'p': 0.09090909090909091,\n",
       "   'f': 0.09999999505000023},\n",
       "  'rouge-l': {'r': 0.2222222222222222, 'p': 0.2, 'f': 0.21052631080332423}}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.get_scores(\n",
    "    train_comparisons.summary_1[0], train_comparisons.ref_summary[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have made sure my mother is comfortable with my boyfriend travelling on a trip and now my mother is mad because I booked it.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comparisons.summary_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>batch</th>\n",
       "      <th>split</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>subsource</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>summary_0</th>\n",
       "      <th>policy_0</th>\n",
       "      <th>note_0</th>\n",
       "      <th>summary_1</th>\n",
       "      <th>policy_1</th>\n",
       "      <th>note_1</th>\n",
       "      <th>confidence</th>\n",
       "      <th>choice</th>\n",
       "      <th>ref_summary</th>\n",
       "      <th>m1_rouge_1_f</th>\n",
       "      <th>m1_rouge_2_f</th>\n",
       "      <th>m1_rouge_l_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_34xale</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>Mother  not speaking to me  because of a trip ...</td>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>Mum is mad at me for not flying on my own trip...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I have made sure my mother is comfortable with...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_34xale</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>Mother  not speaking to me  because of a trip ...</td>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>I have made sure my mother is comfortable with...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>ref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_34xale</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>Mother  not speaking to me  because of a trip ...</td>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>ref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mum thought I was going to road trip with my b...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_34xale</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>Mother  not speaking to me  because of a trip ...</td>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>Mum thought I was going to road trip with my b...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mum is mad at me for not flying on my own trip...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LjvoXOAj5op3WqNnn5b7TZTG8mK7gM</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_1zwek5</td>\n",
       "      <td>reddit</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>Can I sue my property management company and l...</td>\n",
       "      <td>My landlord left a falsified message taped to ...</td>\n",
       "      <td>My landlord is harassing me and my neighbours ...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>landlord pretended to be another tenant and wr...</td>\n",
       "      <td>ref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>landlord pretended to be another tenant and wr...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>RgH765FRFOQZNXPAK7ZzTlIAnj8UD2</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_lg5fp</td>\n",
       "      <td>reddit</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>Calling all therapists, care workers, psycholo...</td>\n",
       "      <td>I am about to start some voluntary work at an ...</td>\n",
       "      <td>Looking for advice and links on working with p...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Need advice on what I should do to better help...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Starting voluntary work at art centre for peop...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>RgH765FRFOQZNXPAK7ZzTlIAnj8UD2</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_lg5fp</td>\n",
       "      <td>reddit</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>Calling all therapists, care workers, psycholo...</td>\n",
       "      <td>I am about to start some voluntary work at an ...</td>\n",
       "      <td>Starting voluntary work at art centre for peop...</td>\n",
       "      <td>ref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Basically anyone who works in a group setting ...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Starting voluntary work at art centre for peop...</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.275862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>RgH765FRFOQZNXPAK7ZzTlIAnj8UD2</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_lg5fp</td>\n",
       "      <td>reddit</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>Calling all therapists, care workers, psycholo...</td>\n",
       "      <td>I am about to start some voluntary work at an ...</td>\n",
       "      <td>Basically anyone who works in a group setting ...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Looking for advice and links on working with p...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Starting voluntary work at art centre for peop...</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>RgH765FRFOQZNXPAK7ZzTlIAnj8UD2</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_2tlc7y</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>I [23 M] am really happy with my long distance...</td>\n",
       "      <td>I've been learning Spanish on my own, and, in ...</td>\n",
       "      <td>I'm really into a girl, but have no idea what ...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Met girl online. Never met in real life. Super...</td>\n",
       "      <td>ref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Met girl online. Never met in real life. Super...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>RgH765FRFOQZNXPAK7ZzTlIAnj8UD2</td>\n",
       "      <td>batch3</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_2tlc7y</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationships</td>\n",
       "      <td>I [23 M] am really happy with my long distance...</td>\n",
       "      <td>I've been learning Spanish on my own, and, in ...</td>\n",
       "      <td>Met girl online. Never met in real life. Super...</td>\n",
       "      <td>ref</td>\n",
       "      <td>NaN</td>\n",
       "      <td>met girl online, we hit it off really well, is...</td>\n",
       "      <td>sup1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Met girl online. Never met in real life. Super...</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              worker   batch  split         id  source  \\\n",
       "0     qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  batch3  train  t3_34xale  reddit   \n",
       "1     qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  batch3  train  t3_34xale  reddit   \n",
       "2     qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  batch3  train  t3_34xale  reddit   \n",
       "3     qo6WIyEh27cwAjWpA3Q60J7NaDxzQJ  batch3  train  t3_34xale  reddit   \n",
       "4     LjvoXOAj5op3WqNnn5b7TZTG8mK7gM  batch3  train  t3_1zwek5  reddit   \n",
       "...                              ...     ...    ...        ...     ...   \n",
       "3995  RgH765FRFOQZNXPAK7ZzTlIAnj8UD2  batch3  train   t3_lg5fp  reddit   \n",
       "3996  RgH765FRFOQZNXPAK7ZzTlIAnj8UD2  batch3  train   t3_lg5fp  reddit   \n",
       "3997  RgH765FRFOQZNXPAK7ZzTlIAnj8UD2  batch3  train   t3_lg5fp  reddit   \n",
       "3998  RgH765FRFOQZNXPAK7ZzTlIAnj8UD2  batch3  train  t3_2tlc7y  reddit   \n",
       "3999  RgH765FRFOQZNXPAK7ZzTlIAnj8UD2  batch3  train  t3_2tlc7y  reddit   \n",
       "\n",
       "          subsource                                              title  \\\n",
       "0     relationships  Mother  not speaking to me  because of a trip ...   \n",
       "1     relationships  Mother  not speaking to me  because of a trip ...   \n",
       "2     relationships  Mother  not speaking to me  because of a trip ...   \n",
       "3     relationships  Mother  not speaking to me  because of a trip ...   \n",
       "4         AskReddit  Can I sue my property management company and l...   \n",
       "...             ...                                                ...   \n",
       "3995      AskReddit  Calling all therapists, care workers, psycholo...   \n",
       "3996      AskReddit  Calling all therapists, care workers, psycholo...   \n",
       "3997      AskReddit  Calling all therapists, care workers, psycholo...   \n",
       "3998  relationships  I [23 M] am really happy with my long distance...   \n",
       "3999  relationships  I [23 M] am really happy with my long distance...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     My boyfriend and I are long distance. We have ...   \n",
       "1     My boyfriend and I are long distance. We have ...   \n",
       "2     My boyfriend and I are long distance. We have ...   \n",
       "3     My boyfriend and I are long distance. We have ...   \n",
       "4     My landlord left a falsified message taped to ...   \n",
       "...                                                 ...   \n",
       "3995  I am about to start some voluntary work at an ...   \n",
       "3996  I am about to start some voluntary work at an ...   \n",
       "3997  I am about to start some voluntary work at an ...   \n",
       "3998  I've been learning Spanish on my own, and, in ...   \n",
       "3999  I've been learning Spanish on my own, and, in ...   \n",
       "\n",
       "                                              summary_0 policy_0 note_0  \\\n",
       "0     Mum is mad at me for not flying on my own trip...     sup1    NaN   \n",
       "1     I have made sure my mother is comfortable with...     sup1    NaN   \n",
       "2     mum isn't speaking to me because I booked a fl...      ref    NaN   \n",
       "3     Mum thought I was going to road trip with my b...     sup1    NaN   \n",
       "4     My landlord is harassing me and my neighbours ...     sup1    NaN   \n",
       "...                                                 ...      ...    ...   \n",
       "3995  Looking for advice and links on working with p...     sup1    NaN   \n",
       "3996  Starting voluntary work at art centre for peop...      ref    NaN   \n",
       "3997  Basically anyone who works in a group setting ...     sup1    NaN   \n",
       "3998  I'm really into a girl, but have no idea what ...     sup1    NaN   \n",
       "3999  Met girl online. Never met in real life. Super...      ref    NaN   \n",
       "\n",
       "                                              summary_1 policy_1 note_1  \\\n",
       "0     I have made sure my mother is comfortable with...     sup1    NaN   \n",
       "1     mum isn't speaking to me because I booked a fl...      ref    NaN   \n",
       "2     Mum thought I was going to road trip with my b...     sup1    NaN   \n",
       "3     Mum is mad at me for not flying on my own trip...     sup1    NaN   \n",
       "4     landlord pretended to be another tenant and wr...      ref    NaN   \n",
       "...                                                 ...      ...    ...   \n",
       "3995  Need advice on what I should do to better help...     sup1    NaN   \n",
       "3996  Basically anyone who works in a group setting ...     sup1    NaN   \n",
       "3997  Looking for advice and links on working with p...     sup1    NaN   \n",
       "3998  Met girl online. Never met in real life. Super...      ref    NaN   \n",
       "3999  met girl online, we hit it off really well, is...     sup1    NaN   \n",
       "\n",
       "      confidence  choice                                        ref_summary  \\\n",
       "0            NaN       1  mum isn't speaking to me because I booked a fl...   \n",
       "1            NaN       1  mum isn't speaking to me because I booked a fl...   \n",
       "2            NaN       0  mum isn't speaking to me because I booked a fl...   \n",
       "3            NaN       0  mum isn't speaking to me because I booked a fl...   \n",
       "4            NaN       1  landlord pretended to be another tenant and wr...   \n",
       "...          ...     ...                                                ...   \n",
       "3995         NaN       0  Starting voluntary work at art centre for peop...   \n",
       "3996         NaN       0  Starting voluntary work at art centre for peop...   \n",
       "3997         NaN       1  Starting voluntary work at art centre for peop...   \n",
       "3998         NaN       1  Met girl online. Never met in real life. Super...   \n",
       "3999         NaN       0  Met girl online. Never met in real life. Super...   \n",
       "\n",
       "      m1_rouge_1_f  m1_rouge_2_f  m1_rouge_l_f  \n",
       "0         0.368421      0.100000      0.210526  \n",
       "1         1.000000      1.000000      1.000000  \n",
       "2         0.325581      0.000000      0.279070  \n",
       "3         0.363636      0.181818      0.303030  \n",
       "4         1.000000      1.000000      1.000000  \n",
       "...            ...           ...           ...  \n",
       "3995      0.375000      0.266667      0.312500  \n",
       "3996      0.344828      0.142857      0.275862  \n",
       "3997      0.538462      0.320000      0.461538  \n",
       "3998      1.000000      1.000000      1.000000  \n",
       "3999      0.153846      0.000000      0.153846  \n",
       "\n",
       "[4000 rows x 20 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_rouge_scores(train_comparisons.iloc[:4000], 'summary_1', 'ref_summary', 'm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-6d5afee35b2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_comparisons\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrouge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'summary_0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ref_summary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--- %s seconds ---\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8837\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8838\u001b[0m         )\n\u001b[1;32m-> 8839\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"apply\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8841\u001b[0m     def applymap(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 851\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-6d5afee35b2b>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_comparisons\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrouge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'summary_0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ref_summary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--- %s seconds ---\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\rouge\\rouge.py\u001b[0m in \u001b[0;36mget_scores\u001b[1;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_avg_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\rouge\\rouge.py\u001b[0m in \u001b[0;36m_get_scores\u001b[1;34m(self, hyps, refs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mhyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhyp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train_comparisons[:4000].apply(lambda x: rouge.get_scores(x['summary_0'], x['ref_summary']), axis=1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.3333333333333333, 'p': 0.4, 'f': 0.36363635867768596},\n",
       "  'rouge-2': {'r': 0.16666666666666666, 'p': 0.2, 'f': 0.18181817685950424},\n",
       "  'rouge-l': {'r': 0.2777777777777778,\n",
       "   'p': 0.3333333333333333,\n",
       "   'f': 0.30303029807162535}}]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comparisons[:1].apply(lambda x: rouge.get_scores(x['summary_0'], x['ref_summary']), axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary_0</th>\n",
       "      <th>ref_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mum is mad at me for not flying on my own trip...</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have made sure my mother is comfortable with...</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mum thought I was going to road trip with my b...</td>\n",
       "      <td>mum isn't speaking to me because I booked a fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My landlord is harassing me and my neighbours ...</td>\n",
       "      <td>landlord pretended to be another tenant and wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92820</th>\n",
       "      <td>Thought about trying to get out of work by bre...</td>\n",
       "      <td>Thought about trying to get out of work by bre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92821</th>\n",
       "      <td>TIFU by accidentily spilling half a glass of w...</td>\n",
       "      <td>Thought about trying to get out of work by bre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92822</th>\n",
       "      <td>TIFU by trying to get out of an assignment by ...</td>\n",
       "      <td>Thought about trying to get out of work by bre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92823</th>\n",
       "      <td>Thought about trying to get out of work by bre...</td>\n",
       "      <td>Thought about trying to get out of work by bre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92824</th>\n",
       "      <td>TIFU by accidentily spilling half a glass of w...</td>\n",
       "      <td>Thought about trying to get out of work by bre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92825 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               summary_0  \\\n",
       "0      Mum is mad at me for not flying on my own trip...   \n",
       "1      I have made sure my mother is comfortable with...   \n",
       "2      mum isn't speaking to me because I booked a fl...   \n",
       "3      Mum thought I was going to road trip with my b...   \n",
       "4      My landlord is harassing me and my neighbours ...   \n",
       "...                                                  ...   \n",
       "92820  Thought about trying to get out of work by bre...   \n",
       "92821  TIFU by accidentily spilling half a glass of w...   \n",
       "92822  TIFU by trying to get out of an assignment by ...   \n",
       "92823  Thought about trying to get out of work by bre...   \n",
       "92824  TIFU by accidentily spilling half a glass of w...   \n",
       "\n",
       "                                             ref_summary  \n",
       "0      mum isn't speaking to me because I booked a fl...  \n",
       "1      mum isn't speaking to me because I booked a fl...  \n",
       "2      mum isn't speaking to me because I booked a fl...  \n",
       "3      mum isn't speaking to me because I booked a fl...  \n",
       "4      landlord pretended to be another tenant and wr...  \n",
       "...                                                  ...  \n",
       "92820  Thought about trying to get out of work by bre...  \n",
       "92821  Thought about trying to get out of work by bre...  \n",
       "92822  Thought about trying to get out of work by bre...  \n",
       "92823  Thought about trying to get out of work by bre...  \n",
       "92824  Thought about trying to get out of work by bre...  \n",
       "\n",
       "[92825 rows x 2 columns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comparisons[['summary_0', 'ref_summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity\n",
    "# BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, text in train_comparisons.groupby('text'):\n",
    "    text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>batch</th>\n",
       "      <th>split</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>subsource</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>summary_0</th>\n",
       "      <th>policy_0</th>\n",
       "      <th>note_0</th>\n",
       "      <th>summary_1</th>\n",
       "      <th>policy_1</th>\n",
       "      <th>note_1</th>\n",
       "      <th>confidence</th>\n",
       "      <th>choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69096</th>\n",
       "      <td>ZzGCcAhvqF0HnKxNsUjtJFadcZdyZj</td>\n",
       "      <td>batch6</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_3rj2k6</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>I (F29) own my own business. This is great, ex...</td>\n",
       "      <td>x-posted to /r/relationships\\n\\nI started my o...</td>\n",
       "      <td>Owns company, makes a lot of money, great cow...</td>\n",
       "      <td>sup2_bo8_rm1</td>\n",
       "      <td>Quoted line is quite unclear.</td>\n",
       "      <td>I'm a woman over 30 who makes more than her m...</td>\n",
       "      <td>sup3_6b</td>\n",
       "      <td>What does the author want to get fixed?</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69097</th>\n",
       "      <td>ZzGCcAhvqF0HnKxNsUjtJFadcZdyZj</td>\n",
       "      <td>batch6</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_3rj2k6</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>I (F29) own my own business. This is great, ex...</td>\n",
       "      <td>x-posted to /r/relationships\\n\\nI started my o...</td>\n",
       "      <td>I'm a woman over 30 who makes more than her m...</td>\n",
       "      <td>sup3_6b</td>\n",
       "      <td>What does the author want to get fixed?</td>\n",
       "      <td>I (F29) own my own business and do very well ...</td>\n",
       "      <td>ref</td>\n",
       "      <td>OK</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69098</th>\n",
       "      <td>ZzGCcAhvqF0HnKxNsUjtJFadcZdyZj</td>\n",
       "      <td>batch6</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_3rj2k6</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>I (F29) own my own business. This is great, ex...</td>\n",
       "      <td>x-posted to /r/relationships\\n\\nI started my o...</td>\n",
       "      <td>I make a lot of money, but I can't get guys t...</td>\n",
       "      <td>sup2</td>\n",
       "      <td>OK</td>\n",
       "      <td>I'm a woman over 30 who makes more than her m...</td>\n",
       "      <td>sup3_6b</td>\n",
       "      <td>What does the author want to get fixed?</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69099</th>\n",
       "      <td>ZzGCcAhvqF0HnKxNsUjtJFadcZdyZj</td>\n",
       "      <td>batch6</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_3rj2k6</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>I (F29) own my own business. This is great, ex...</td>\n",
       "      <td>x-posted to /r/relationships\\n\\nI started my o...</td>\n",
       "      <td>I make a lot of money, but I can't get guys t...</td>\n",
       "      <td>sup2</td>\n",
       "      <td>OK</td>\n",
       "      <td>I (F29) own my own business and do very well ...</td>\n",
       "      <td>ref</td>\n",
       "      <td>OK</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69100</th>\n",
       "      <td>ZzGCcAhvqF0HnKxNsUjtJFadcZdyZj</td>\n",
       "      <td>batch6</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_3rj2k6</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>I (F29) own my own business. This is great, ex...</td>\n",
       "      <td>x-posted to /r/relationships\\n\\nI started my o...</td>\n",
       "      <td>I make a lot of money, but I can't get guys t...</td>\n",
       "      <td>sup2</td>\n",
       "      <td>OK</td>\n",
       "      <td>Owns company, makes a lot of money, great cow...</td>\n",
       "      <td>sup2_bo8_rm1</td>\n",
       "      <td>Quoted line is quite unclear.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69101</th>\n",
       "      <td>ZzGCcAhvqF0HnKxNsUjtJFadcZdyZj</td>\n",
       "      <td>batch6</td>\n",
       "      <td>train</td>\n",
       "      <td>t3_3rj2k6</td>\n",
       "      <td>reddit</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>I (F29) own my own business. This is great, ex...</td>\n",
       "      <td>x-posted to /r/relationships\\n\\nI started my o...</td>\n",
       "      <td>Owns company, makes a lot of money, great cow...</td>\n",
       "      <td>sup2_bo8_rm1</td>\n",
       "      <td>Quoted line is quite unclear.</td>\n",
       "      <td>I (F29) own my own business and do very well ...</td>\n",
       "      <td>ref</td>\n",
       "      <td>OK</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               worker   batch  split         id  source  \\\n",
       "69096  ZzGCcAhvqF0HnKxNsUjtJFadcZdyZj  batch6  train  t3_3rj2k6  reddit   \n",
       "69097  ZzGCcAhvqF0HnKxNsUjtJFadcZdyZj  batch6  train  t3_3rj2k6  reddit   \n",
       "69098  ZzGCcAhvqF0HnKxNsUjtJFadcZdyZj  batch6  train  t3_3rj2k6  reddit   \n",
       "69099  ZzGCcAhvqF0HnKxNsUjtJFadcZdyZj  batch6  train  t3_3rj2k6  reddit   \n",
       "69100  ZzGCcAhvqF0HnKxNsUjtJFadcZdyZj  batch6  train  t3_3rj2k6  reddit   \n",
       "69101  ZzGCcAhvqF0HnKxNsUjtJFadcZdyZj  batch6  train  t3_3rj2k6  reddit   \n",
       "\n",
       "                 subsource                                              title  \\\n",
       "69096  relationship_advice  I (F29) own my own business. This is great, ex...   \n",
       "69097  relationship_advice  I (F29) own my own business. This is great, ex...   \n",
       "69098  relationship_advice  I (F29) own my own business. This is great, ex...   \n",
       "69099  relationship_advice  I (F29) own my own business. This is great, ex...   \n",
       "69100  relationship_advice  I (F29) own my own business. This is great, ex...   \n",
       "69101  relationship_advice  I (F29) own my own business. This is great, ex...   \n",
       "\n",
       "                                                    text  \\\n",
       "69096  x-posted to /r/relationships\\n\\nI started my o...   \n",
       "69097  x-posted to /r/relationships\\n\\nI started my o...   \n",
       "69098  x-posted to /r/relationships\\n\\nI started my o...   \n",
       "69099  x-posted to /r/relationships\\n\\nI started my o...   \n",
       "69100  x-posted to /r/relationships\\n\\nI started my o...   \n",
       "69101  x-posted to /r/relationships\\n\\nI started my o...   \n",
       "\n",
       "                                               summary_0      policy_0  \\\n",
       "69096   Owns company, makes a lot of money, great cow...  sup2_bo8_rm1   \n",
       "69097   I'm a woman over 30 who makes more than her m...       sup3_6b   \n",
       "69098   I make a lot of money, but I can't get guys t...          sup2   \n",
       "69099   I make a lot of money, but I can't get guys t...          sup2   \n",
       "69100   I make a lot of money, but I can't get guys t...          sup2   \n",
       "69101   Owns company, makes a lot of money, great cow...  sup2_bo8_rm1   \n",
       "\n",
       "                                        note_0  \\\n",
       "69096            Quoted line is quite unclear.   \n",
       "69097  What does the author want to get fixed?   \n",
       "69098                                       OK   \n",
       "69099                                       OK   \n",
       "69100                                       OK   \n",
       "69101            Quoted line is quite unclear.   \n",
       "\n",
       "                                               summary_1      policy_1  \\\n",
       "69096   I'm a woman over 30 who makes more than her m...       sup3_6b   \n",
       "69097   I (F29) own my own business and do very well ...           ref   \n",
       "69098   I'm a woman over 30 who makes more than her m...       sup3_6b   \n",
       "69099   I (F29) own my own business and do very well ...           ref   \n",
       "69100   Owns company, makes a lot of money, great cow...  sup2_bo8_rm1   \n",
       "69101   I (F29) own my own business and do very well ...           ref   \n",
       "\n",
       "                                        note_1  confidence  choice  \n",
       "69096  What does the author want to get fixed?         6.0       1  \n",
       "69097                                       OK         9.0       1  \n",
       "69098  What does the author want to get fixed?         4.0       0  \n",
       "69099                                       OK         9.0       1  \n",
       "69100            Quoted line is quite unclear.         4.0       0  \n",
       "69101                                       OK         9.0       1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
